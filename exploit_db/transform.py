# transform_exploitdb.py
import csv
import io
import json
import re
from datetime import datetime
from typing import List, Dict, Tuple, Any

CVE_RE = re.compile(r"(CVE-\d{4}-\d{4,7})", re.IGNORECASE)

def _extract_first_cve(codes_field: Any) -> str | None:
    if codes_field is None:
        return None
    if isinstance(codes_field, (list, tuple)):
        s = ";".join(map(str, codes_field))
    else:
        s = str(codes_field)
    m = CVE_RE.search(s)
    return m.group(1).upper() if m else None

def _date_only_from_any(s: Any) -> str | None:
    """
    Normalize many date forms to YYYY-MM-DD (date only). If not parseable, return None.
    We accept ISO (with T), space-separated, or already YYYY-MM-DD.
    """
    if s is None:
        return None
    try:
        s = str(s).strip()
        if not s:
            return None
        # If contains T or space, cut to date portion
        if "T" in s:
            s = s.split("T", 1)[0]
        if " " in s:
            s = s.split(" ", 1)[0]
        # If s is like DD/MM/YYYY or other formats, try some common formats
        # Prefer YYYY-MM-DD as canonical
        # If already YYYY-MM-DD length 10 and has dashes, accept
        if len(s) >= 10 and s[4] == "-" and s[7] == "-":
            return s[:10]
        # Try parsing other known patterns
        for fmt in ("%Y-%m-%d", "%Y/%m/%d", "%d-%m-%Y", "%d/%m/%Y", "%m/%d/%Y"):
            try:
                dt = datetime.strptime(s[:10], fmt)
                return dt.strftime("%Y-%m-%d")
            except Exception:
                continue
        # fallback: try full parse
        try:
            dt = datetime.fromisoformat(s)
            return dt.strftime("%Y-%m-%d")
        except Exception:
            return None
    except Exception:
        return None

def transform_csv_text_to_records_and_json_bytes(csv_text: str) -> Tuple[List[Dict[str, Any]], bytes]:
    f = io.StringIO(csv_text)
    sample = f.read(8192)
    f.seek(0)
    try:
        dialect = csv.Sniffer().sniff(sample)
        f.seek(0)
    except Exception:
        dialect = csv.excel
        f.seek(0)

    reader = csv.DictReader(f, dialect=dialect)
    records: List[Dict[str, Any]] = []
    today = datetime.utcnow().strftime("%Y-%m-%d")

    for row in reader:
        normalized = { (k.strip() if k else k): (v if v is not None else None) for k,v in row.items() }
        _id = normalized.get("id") or normalized.get("ID") or normalized.get("Id")
        if not _id or str(_id).strip() == "":
            continue

        # Extract a CVE if present
        codes_field = None
        for candidate in ("codes", "codes ", "CVE_id", "CVE id", "cves", "codes_cve"):
            if candidate in normalized and normalized[candidate]:
                codes_field = normalized[candidate]
                break
        cve = _extract_first_cve(codes_field)

        # Normalize string fields
        for k, v in list(normalized.items()):
            if isinstance(v, str):
                normalized[k] = v.strip()

        normalized["id"] = str(_id).strip()
        normalized["CVE_id"] = cve

        # Determine a canonical date_updated:
        # Prefer feed columns such as date_published, date_added, date or uploaded_date
        date_candidate = None
        for candidate in ("date_published", "date_published ", "date_published(utc)", "date_added", "date", "date_published", "uploaded_date", "uploaded"):
            if candidate in normalized and normalized[candidate]:
                date_candidate = normalized[candidate]
                break
        if not date_candidate:
            # try some other likely keys
            for k in ("Date", "published_date", "created_at"):
                if k in normalized and normalized[k]:
                    date_candidate = normalized[k]
                    break

        date_only = _date_only_from_any(date_candidate)
        normalized["date_updated"] = date_only or today

        # Keep uploaded_date for bookkeeping (volatile) too
        normalized.setdefault("uploaded_date", today)

        records.append(normalized)

    json_bytes = json.dumps(records, ensure_ascii=False, indent=2).encode("utf-8")
    print(f"ðŸ”„ Transformed CSV -> records: {len(records)} rows, json bytes {len(json_bytes)}")
    return records, json_bytes
